WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.679
既然 HMM 可以用 为什么我们还需要新模型呢？

00:00:04.679 --> 00:00:06.809
这就与潜力有关了

00:00:06.809 --> 00:00:11.945
假设我们不缺数据 也不缺处理能力

00:00:11.945 --> 00:00:14.804
HMM 模型可以走多远呢？

00:00:14.804 --> 00:00:17.879
其它模型又能走多远呢？

00:00:17.879 --> 00:00:22.535
据百度 Adam Coates 在最近的展示里称

00:00:22.535 --> 00:00:27.399
就算对传统 ASR 额外施加训练 准确率也提高不了

00:00:27.399 --> 00:00:31.559
而深度神经网络虽然在处理小数据集时平平无奇

00:00:31.559 --> 00:00:37.000
可一旦数据增加 模型加大 这种网络就能大放异彩

00:00:37.000 --> 00:00:39.554
这是我们到目前为止说到的过程

00:00:39.554 --> 00:00:44.465
用 MFCC 从音频语音信号里提取特征

00:00:44.465 --> 00:00:50.280
用 HMM 声学模型把特征转化成声音单位、音素或单词

00:00:50.280 --> 00:00:54.000
然后用数据语言模型 如 N 元模型

00:00:54.000 --> 00:00:58.500
来解决语义模糊问题 生成最终的文本序列

00:00:58.500 --> 00:01:03.929
如果用多层深度神经网络 这其中的许多调整部分都可以替换掉

00:01:03.929 --> 00:01:07.484
我们来看为什么这些部分可以替换

00:01:07.484 --> 00:01:10.920
特征提取时 我们用的模型

00:01:10.920 --> 00:01:15.685
会根据人体发声机制和声音感知机制来将频谱图转为特征

00:01:15.685 --> 00:01:17.850
这听起来与用卷积神经网络

00:01:17.849 --> 00:01:23.625
从图像数据里提取特征的思路很类似

00:01:23.625 --> 00:01:27.694
频谱图就是语音的视觉表示

00:01:27.694 --> 00:01:30.449
所以我们应该能让 CNN

00:01:30.450 --> 00:01:34.094
用同样的办法找出相应的语音特征

00:01:34.094 --> 00:01:37.814
与 HMM 一起实现的声学模型

00:01:37.814 --> 00:01:42.194
是用转换概率来组织时序数据的

00:01:42.194 --> 00:01:46.989
而借助记忆 循环神经网络也能跟踪时序数据

00:01:46.989 --> 00:01:50.429
这点在之前的 RNN 课程里讲过

00:01:50.430 --> 00:01:55.900
传统模型还用 HMM 来排序声音单元 使之成为单词

00:01:55.900 --> 00:02:00.859
但 RNN 则是生成各时间切片的概率密度

00:02:00.859 --> 00:02:04.224
所以我们需要另找办法来解决排序问题

00:02:04.224 --> 00:02:07.559
联结主义时序分类层

00:02:07.560 --> 00:02:11.400
就用于将 RNN 输出转换成单词

00:02:11.400 --> 00:02:14.890
所以我们可以把网络的声学部分

00:02:14.889 --> 00:02:19.569
替换成 RNN 与 CTC 层的组合

00:02:19.569 --> 00:02:23.775
端对端深度神经网络仍会有语言学错误

00:02:23.775 --> 00:02:28.385
特别是对样本不够充分的单词

00:02:28.384 --> 00:02:32.234
系统可以从音频数据中学习语言概率

00:02:32.235 --> 00:02:36.570
但目前来说样本仍不够

00:02:36.569 --> 00:02:40.479
所以我们仍可以用现有的 N 元技术

00:02:40.479 --> 00:02:47.114
另外 可以用数量庞大的文本来训练神经语言模型 (NLM)

00:02:47.115 --> 00:02:49.628
使用 NLM 层

00:02:49.627 --> 00:02:54.229
我们就可以重新为系统算出拼写和语境概率了

