WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.109
现在我们来看看解码器部分

00:00:03.109 --> 00:00:04.984
在不具有注意力机制的模型中

00:00:04.985 --> 00:00:09.269
除了结束标记的嵌入之外

00:00:09.269 --> 00:00:11.855
我们仅将最后一个语境向量馈送给解码器 RNN

00:00:11.855 --> 00:00:17.079
它将开始在每个时间步生成输出序列的一个元素

00:00:17.079 --> 00:00:21.364
但是具有注意力机制的解码器有所不同

00:00:21.364 --> 00:00:26.364
注意力解码器能够查看输入的单词

00:00:26.364 --> 00:00:28.684
以及解码器自己的隐藏状态

00:00:28.684 --> 00:00:30.734
然后执行以下操作

00:00:30.734 --> 00:00:37.189
它将使用一个评分函数对语境矩阵中的每个隐藏状态评分

00:00:37.189 --> 00:00:39.780
稍后我们将讲解评分函数

00:00:39.780 --> 00:00:43.355
每次评分之后 每个语境向量就生成一个得分

00:00:43.354 --> 00:00:47.640
如果我们将这些得分馈送给一个 softmax 函数

00:00:47.640 --> 00:00:50.179
就会获得全为正数的得分

00:00:50.179 --> 00:00:52.015
全在 0 和 1 之间

00:00:52.015 --> 00:00:53.670
并且所有数值之和为 1

00:00:53.670 --> 00:00:57.980
这些值表示每个向量在注意力向量中的表示程度

00:00:57.979 --> 00:01:02.434
并且解码器在生成输出之前会查看这些注意力向量

00:01:02.435 --> 00:01:07.730
只需将每个向量与其 softmax 得分相乘

00:01:07.730 --> 00:01:13.400
然后将这些向量相加 得出注意力语境向量

00:01:13.400 --> 00:01:16.495
这是一种基本加权和运算

00:01:16.495 --> 00:01:20.765
语境向量是这个流程的重要组成部分

00:01:20.765 --> 00:01:22.299
但并不是最终目标

00:01:22.299 --> 00:01:26.149
在下个视频中 我们将了解语境向量

00:01:26.150 --> 00:01:31.609
如何与解码器隐藏状态合并 在时间步创建解码器的真实输出

00:01:31.609 --> 00:01:38.914
解码器现在查看了输入单词和注意力语境向量

00:01:38.915 --> 00:01:43.570
而注意力语境向量集中查看的是输入序列的相应位置

00:01:43.569 --> 00:01:49.839
它输出隐藏状态并生成输出序列的第一个单词

00:01:49.840 --> 00:01:52.780
这依然是过于简化的图形

00:01:52.780 --> 00:01:54.935
因此在这里添加了星号

00:01:54.935 --> 00:01:57.109
在 RNN 和最终输出之间

00:01:57.108 --> 00:01:58.834
依然有一个步骤

00:01:58.834 --> 00:02:02.114
我们将在下个视频中讨论

00:02:02.114 --> 00:02:04.414
在下个时间步

00:02:04.415 --> 00:02:08.724
RNN 将之前的输出作为输入

00:02:08.724 --> 00:02:12.919
为该时间步生成自己的语境向量

00:02:12.919 --> 00:02:15.664
以及上个时间步的隐藏状态

00:02:15.664 --> 00:02:19.789
并为解码器生成新的隐藏状态

00:02:19.789 --> 00:02:23.025
以及输出序列中的新单词

00:02:23.025 --> 00:02:27.330
一直持续下去 直到完成输出序列

