WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.645
我们详细了解下自注意力的原理

00:00:03.645 --> 00:00:05.669
假设我们希望编码器阅读这些单词

00:00:05.669 --> 00:00:09.120
并创建表示结果

00:00:09.119 --> 00:00:13.469
和之前一样 首先将它们嵌入为向量

00:00:13.470 --> 00:00:18.125
因为 Transformer 使我们能够非常灵活地并行处理

00:00:18.125 --> 00:00:21.134
这个示例假设进程或 GPU

00:00:21.135 --> 00:00:25.530
对输入序列的第二个单词进行编码

00:00:25.530 --> 00:00:27.570
第一步是比较它们

00:00:27.570 --> 00:00:29.910
我们通过相互比较对嵌入评分

00:00:29.910 --> 00:00:32.009
这是一个得分 这是一个得分

00:00:32.009 --> 00:00:34.710
将当前正在阅读或编码的这个单词

00:00:34.710 --> 00:00:37.730
与输入序列中的其他单词进行比较

00:00:37.729 --> 00:00:39.674
对得分进行缩放

00:00:39.674 --> 00:00:41.809
这里是除以 2

00:00:41.810 --> 00:00:43.240
即键的大小

00:00:43.240 --> 00:00:46.240
这里使用的是示例维度 4

00:00:46.240 --> 00:00:48.490
因此这里是 2

00:00:48.490 --> 00:00:51.710
对它们应用 softmax

00:00:51.710 --> 00:00:53.810
然后将 softmax 得分与嵌入相乘

00:00:53.810 --> 00:00:57.615
获得每个向量的表达级别

00:00:57.615 --> 00:01:01.435
当前单词的嵌入直接按原样传入

00:01:01.435 --> 00:01:07.700
相加 生成自注意力语境向量

00:01:07.700 --> 00:01:10.230
如果要取个名称的话

00:01:10.230 --> 00:01:13.340
当该论文的作者第一次在 NIPS 大会上

00:01:13.340 --> 00:01:17.015
公布这篇论文时 他们展现了这个图像

00:01:17.015 --> 00:01:20.545
然后 我们查看第二个单词

00:01:20.545 --> 00:01:22.560
这些是单词

00:01:22.560 --> 00:01:24.475
这些是嵌入

00:01:24.474 --> 00:01:27.309
这些是嵌入向量

00:01:27.310 --> 00:01:34.325
将这个单词与输入向量中的每个其他单词进行比较或对其评分

00:01:34.325 --> 00:01:39.265
然后将这个得分与该相关单词的嵌入相乘

00:01:39.265 --> 00:01:41.424
将所有这些结果相加

00:01:41.424 --> 00:01:44.164
我们没有对当前单词评分

00:01:44.165 --> 00:01:46.130
而是对所有其他单词评分

00:01:46.129 --> 00:01:51.409
将它们相加后 将这个传入前馈神经网络

00:01:51.409 --> 00:01:53.019
但是 如果这么实施的话

00:01:53.019 --> 00:01:57.269
可以看出 如果仅根据单词嵌入判断

00:01:57.269 --> 00:01:59.649
模型主要侧重于其他相似单词

00:01:59.650 --> 00:02:02.810
因此这里需要做个小小的修改

00:02:02.810 --> 00:02:05.920
我们需要通过每个嵌入创建查询

00:02:05.920 --> 00:02:10.659
为此 我们乘以查询矩阵

00:02:10.659 --> 00:02:16.155
或将其传入查询前馈神经网络

00:02:16.155 --> 00:02:17.895
此外还创建键

00:02:17.895 --> 00:02:21.370
这是另一个单独的键矩阵

00:02:21.370 --> 00:02:23.120
再计算一遍

00:02:23.120 --> 00:02:24.435
这是嵌入

00:02:24.435 --> 00:02:26.265
创建查询

00:02:26.264 --> 00:02:28.134
这里仅处理第二个单词

00:02:28.134 --> 00:02:32.009
因此仅为这个单词创建查询

00:02:32.009 --> 00:02:33.694
然后 这里是键

00:02:33.694 --> 00:02:37.699
评分函数将查询与键进行比较

00:02:37.699 --> 00:02:40.119
获得这些数字

00:02:40.120 --> 00:02:41.724
40 和 26

00:02:41.724 --> 00:02:44.299
进行缩放 应用 softmax

00:02:44.300 --> 00:02:47.545
然后将 softmax 得分与键相乘

00:02:47.544 --> 00:02:53.794
将所有这些相加后 得出自注意力语境向量

00:02:53.794 --> 00:02:55.879
这是可接受的方式

00:02:55.879 --> 00:02:59.294
但是还需要查看另一种版本

00:02:59.294 --> 00:03:01.969
这是嵌入

00:03:01.969 --> 00:03:03.530
这是查询

00:03:03.530 --> 00:03:08.724
通过将嵌入与 Q 矩阵相乘得出查询

00:03:08.724 --> 00:03:11.389
Q 矩阵是在训练流程中学习到的矩阵

00:03:11.389 --> 00:03:18.929
这是键 通过将嵌入与 K 矩阵相乘得出键

00:03:18.930 --> 00:03:21.409
这些是值

00:03:21.409 --> 00:03:24.829
生成方法一样 将嵌入与 v 矩阵相乘

00:03:24.830 --> 00:03:27.295
v 矩阵也是在训练流程中学到的矩阵

00:03:27.294 --> 00:03:31.589
这是作者在论文中及他们的 NIPS 演讲中提供的图形

00:03:31.590 --> 00:03:34.164
他们概述了如何创建键

00:03:34.164 --> 00:03:35.704
查询和值

00:03:35.705 --> 00:03:37.399
这是嵌入

00:03:37.399 --> 00:03:40.300
将其与 v 相乘得出值

00:03:40.300 --> 00:03:42.450
与 q 相乘得出查询

00:03:42.449 --> 00:03:45.854
与 k 相乘得出键

00:03:45.854 --> 00:03:49.079
就像这篇论文中呈现的一样

00:03:49.080 --> 00:03:50.490
自注意力的最终形式

00:03:50.490 --> 00:03:52.265
包括嵌入

00:03:52.264 --> 00:03:53.794
计算出 V Q

00:03:53.794 --> 00:03:56.469
值 键和查询

00:03:56.469 --> 00:03:59.520
通过与键对比对查询评分

00:03:59.520 --> 00:04:03.575
然后将 softmax 得分与值相乘

00:04:03.574 --> 00:04:09.185
将这些相加 传递给前馈神经网络

00:04:09.185 --> 00:04:12.629
这是这个模型的简单概览

00:04:12.629 --> 00:04:16.284
并讨论了自注意力概念

00:04:16.285 --> 00:04:17.725
在视频下方的文本中

00:04:17.725 --> 00:04:20.530
我们提供了该论文和一些实现的链接

00:04:20.529 --> 00:04:24.659
帮助你深入了解 Transformer

