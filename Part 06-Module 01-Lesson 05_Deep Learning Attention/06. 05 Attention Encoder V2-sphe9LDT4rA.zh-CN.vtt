WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.730
我们已经简要地了解了

00:00:02.730 --> 00:00:05.480
序列到序列模型中的注意力机制的原理

00:00:05.480 --> 00:00:07.745
现在更详细地了解该机制

00:00:07.745 --> 00:00:11.160
我们将使用机器翻译作为示例

00:00:11.160 --> 00:00:14.250
因为机器翻译是关于注意力的主要论文解决的问题

00:00:14.250 --> 00:00:15.750
但是我们在本视频中介绍的方法

00:00:15.750 --> 00:00:18.259
也适用于其他应用

00:00:18.260 --> 00:00:22.240
需要注意的是 注意力算法有几种不同类别

00:00:22.239 --> 00:00:24.159
我们将了解的是一个简单的算法

00:00:24.160 --> 00:00:26.214
从编码器开始

00:00:26.214 --> 00:00:29.995
在这个示例中 编码器是一个循环神经网络

00:00:29.995 --> 00:00:31.800
在创建 RNN 时

00:00:31.800 --> 00:00:35.289
我们需要声明 RNN 单元中的隐藏单元数量

00:00:35.289 --> 00:00:40.664
无论是 RNN 还是 LSTM 或 GRU 单元都适用

00:00:40.664 --> 00:00:44.679
在将输入序列单词馈送到编码器中之前

00:00:44.679 --> 00:00:50.149
它们需要经过一个嵌入流程 该流程会将每个单词转换为向量

00:00:50.149 --> 00:00:54.060
这是表示每个单词的向量

00:00:54.060 --> 00:00:59.800
这是一个大小为 4 的示例嵌入 只是为了便于可视化

00:00:59.799 --> 00:01:04.829
在实际应用中 大小更有可能是 200 或 300

00:01:04.829 --> 00:01:09.444
我们将继续使用这些用颜色标注的方框表示向量

00:01:09.444 --> 00:01:13.264
这样屏幕上就不会有太多的数字

00:01:13.265 --> 00:01:17.659
有了单词和嵌入后

00:01:17.659 --> 00:01:20.685
可以将它们馈送到编码器中了

00:01:20.685 --> 00:01:23.420
将第一个单词馈送到 RNN 的第一个时间步

00:01:23.420 --> 00:01:27.555
生成了第一个隐藏状态

00:01:27.555 --> 00:01:31.400
这个称之为 RNN 的展开视图

00:01:31.400 --> 00:01:34.105
我们可以看到每个时间步的 RNN

00:01:34.105 --> 00:01:38.780
我们从这个状态继续 RNN 将继续处理下个时间步

00:01:38.780 --> 00:01:44.329
获取第二个单词并将其传递给第二个时间步的 RNN

00:01:44.329 --> 00:01:47.234
然后对第三个单词重复相同的步骤

00:01:47.234 --> 00:01:50.989
处理完整个输入序列

00:01:50.989 --> 00:01:55.089
可以将隐藏状态传递给注意力解码器了

