WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.415
下面介绍下具有注意力机制的序列到序列模型的原理

00:00:04.415 --> 00:00:08.128
首先 就像没有注意力机制的模型一样

00:00:08.128 --> 00:00:12.279
编码器处理输入序列的方式是一次处理一个单词

00:00:12.279 --> 00:00:16.464
生成隐藏状态并使用该隐藏状态 然后是下个隐藏状态

00:00:16.464 --> 00:00:19.920
接着 模型将语句向量传递给解码器

00:00:19.920 --> 00:00:24.150
但是与不带注意力机制的模型中的语境向量不同的是

00:00:24.149 --> 00:00:28.779
这个状态不再是最终隐藏状态 而是所有隐藏状态

00:00:28.780 --> 00:00:33.359
这样 我们可以灵活地设定语境大小

00:00:33.359 --> 00:00:35.369
长句子可以具有更长的语境向量

00:00:35.369 --> 00:00:40.649
能够更好地捕获输入序列中的信息

00:00:40.649 --> 00:00:46.000
注意力的另一个重要特性是

00:00:46.000 --> 00:00:50.179
每个隐藏状态与生成该单词之前的

00:00:50.179 --> 00:00:55.005
输入序列部分关联性最大

00:00:55.005 --> 00:00:58.785
在处理第一个单词后输出第一个隐藏状态

00:00:58.784 --> 00:01:03.819
它捕获的是第一个单词的关键信息

00:01:03.820 --> 00:01:05.750
当我们侧重于这个向量时

00:01:05.750 --> 00:01:07.829
我们将最侧重于这个单词

00:01:07.829 --> 00:01:14.105
第二个隐藏状态与第二个单词的关系也是这样 然后是第三个单词

00:01:14.105 --> 00:01:16.880
但是最后一个 即第三个向量

00:01:16.879 --> 00:01:21.199
还包含了它前面所有环节的一部分信息

