WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.054
在详细讲解评分函数之前

00:00:04.054 --> 00:00:08.175
我们需要区分下两种主要注意力类型

00:00:08.175 --> 00:00:13.420
通常称之为加法注意力和乘法注意力

00:00:13.419 --> 00:00:17.265
有时候也称为 Bahdanau 注意力和 Luong 注意力

00:00:17.265 --> 00:00:21.750
它们以首次描述这两种类型的论文作者命名

00:00:21.750 --> 00:00:25.214
Bahdanau 注意力是指 Dzmitry Badanau

00:00:25.214 --> 00:00:27.149
他是这篇论文的第一作者

00:00:27.149 --> 00:00:29.820
“Neural machine translation by jointly learning to”

00:00:29.820 --> 00:00:33.274
“align and translate”这篇论文提出了大量这种观点

00:00:33.274 --> 00:00:37.739
Bahdanau 注意力中的评分函数看起来这样

00:00:37.740 --> 00:00:42.204
其中 hj 表示编码器的隐藏状态

00:00:42.204 --> 00:00:50.239
s(i-1) 表示上个时间步的解码器隐藏状态

00:00:50.240 --> 00:00:53.865
Ua Wa 和 va

00:00:53.865 --> 00:00:59.150
都是在训练流程中学习的权重矩阵

00:00:59.149 --> 00:01:01.269
本质上 这个评分函数

00:01:01.270 --> 00:01:04.015
会获取编码器的隐藏状态

00:01:04.015 --> 00:01:05.620
和解码器的隐藏状态

00:01:05.620 --> 00:01:09.990
然后在每个解码器时间步生成一个数字

00:01:09.989 --> 00:01:13.420
如果看起来太复杂 也不用担心

00:01:13.420 --> 00:01:17.170
我们将详细讲解该公式并用图形讲解

00:01:17.170 --> 00:01:19.750
然后将得分传入 softmax 中

00:01:19.750 --> 00:01:21.694
softmax 公式是这样的

00:01:21.694 --> 00:01:25.059
这是加权求和运算

00:01:25.060 --> 00:01:29.254
我们将每个编码器隐藏状态与其得分相乘

00:01:29.254 --> 00:01:32.064
然后求所有值的和

00:01:32.064 --> 00:01:35.299
生成注意力语境向量

00:01:35.299 --> 00:01:40.280
在它们的结构中 编码器是双向 RNN

00:01:40.280 --> 00:01:45.265
通过将这两个图层的状态相连生成编码器向量

00:01:45.265 --> 00:01:48.174
乘法注意力或 Luong 注意力

00:01:48.174 --> 00:01:49.929
是指 Thang Luong

00:01:49.930 --> 00:01:51.820
即以下论文的第一作者

00:01:51.819 --> 00:01:55.459
”Effective Approaches to Attention-based Neural Machine Translation.“

00:01:55.459 --> 00:01:57.640
Luong 注意力以 Bahdanau 注意力为基础

00:01:57.640 --> 00:02:01.265
在其中添加了几个评分函数

00:02:01.265 --> 00:02:04.715
它们的结构也不同 它们仅使用

00:02:04.715 --> 00:02:08.944
编码器中顶部 RNN 图层的隐藏状态

00:02:08.944 --> 00:02:13.829
使得编码器和解码器都是 RNN 堆栈

00:02:13.830 --> 00:02:16.925
稍后我们将在应用视频中看到这一点

00:02:16.925 --> 00:02:21.540
推动了目前正在生产阶段的一些首发模型的推出

00:02:21.539 --> 00:02:27.534
乘法注意力中有三个评分函数可供选择

00:02:27.534 --> 00:02:30.924
最简单的是点乘评分函数

00:02:30.925 --> 00:02:37.775
即将编码器的隐藏状态与解码器的隐藏状态相乘

00:02:37.775 --> 00:02:40.849
第二个评分函数称为通用评分函数

00:02:40.849 --> 00:02:45.889
它以上面的函数为基础 只向其中添加了权重矩阵

00:02:45.889 --> 00:02:47.689
点积中的这个乘法

00:02:47.689 --> 00:02:51.354
正是乘法注意力的得名原因

00:02:51.354 --> 00:02:54.810
第三个与 Bahdanau 注意力很相似

00:02:54.810 --> 00:03:00.319
它将编码器的隐藏状态与解码器的隐藏状态相加

00:03:00.319 --> 00:03:04.479
这个加法正是加法注意力的得名原因

00:03:04.479 --> 00:03:07.709
然后乘以权重矩阵

00:03:07.710 --> 00:03:13.409
应用双曲正切激活函数 然后乘以另一个权重矩阵

00:03:13.409 --> 00:03:17.419
我们为这个时间步的解码器隐藏状态

00:03:17.419 --> 00:03:23.174
和所有时间步的编码器隐藏状态应用这个函数

00:03:23.175 --> 00:03:26.350
并为每个状态生成一个得分

00:03:26.349 --> 00:03:29.465
然后像之前一样应用 softmax

00:03:29.465 --> 00:03:32.700
生成这里的 ct

00:03:32.699 --> 00:03:34.759
它们称为注意力语境函数

00:03:34.759 --> 00:03:39.034
这一步将生成解码器的最终输出

00:03:39.034 --> 00:03:42.259
如果看不懂这些公式的话

00:03:42.259 --> 00:03:45.489
不用担心 我们将在下个视频中以图形的形式讲解一遍

00:03:45.490 --> 00:03:50.150
这是论文中的一个示例

00:03:50.150 --> 00:03:55.034
它比较了注意力方法和之前不具有注意力机制的序列到序列模型

00:03:55.034 --> 00:03:58.555
这是英语到德语翻译

00:03:58.555 --> 00:04:02.939
这是英文原文 这是参考

00:04:02.939 --> 00:04:06.409
这是标签正确德语翻译

00:04:06.409 --> 00:04:07.754
这是模型的流程

00:04:07.754 --> 00:04:10.259
翻译得很好

00:04:10.259 --> 00:04:14.829
这是没有注意力机制的基准模型

00:04:14.830 --> 00:04:18.129
可以看出姓名翻错了

00:04:18.129 --> 00:04:21.903
这个错误可以归结于

00:04:21.903 --> 00:04:26.074
难以获取最后一个编码器隐藏状态中的所有信息

00:04:26.074 --> 00:04:29.254
这是注意力机制的强大之处

00:04:29.254 --> 00:04:33.740
使编码器能够查看输入序列的各个部分

00:04:33.740 --> 00:04:37.129
无论它们在输入序列的前面哪个位置

