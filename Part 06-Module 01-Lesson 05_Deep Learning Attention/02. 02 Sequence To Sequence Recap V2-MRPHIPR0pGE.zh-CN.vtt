WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.330
欢迎回来 在这个视频中

00:00:02.330 --> 00:00:05.984
我们将简单总结下序列到序列模型的原理

00:00:05.985 --> 00:00:11.480
序列到序列模型会接受一个条目序列作为输入

00:00:11.480 --> 00:00:15.675
然后生成另一个条目序列作为输出

00:00:15.675 --> 00:00:18.335
在机器翻译应用中

00:00:18.335 --> 00:00:22.385
输入序列是一种语言的单词系列

00:00:22.385 --> 00:00:26.530
输出是另一种语言的翻译

00:00:26.530 --> 00:00:31.170
在文本摘要中 输入是一个很长的句子

00:00:31.170 --> 00:00:34.310
输出是很短的句子

00:00:34.509 --> 00:00:40.364
序列到序列模型通常由编码器和解码器组成

00:00:40.365 --> 00:00:43.940
工作原理是编码器首先处理所有输入

00:00:43.939 --> 00:00:48.769
将输入变成一个表示结果

00:00:48.770 --> 00:00:51.255
通常是一个向量

00:00:51.255 --> 00:00:53.535
称之为语境向量

00:00:53.534 --> 00:00:56.179
包含编码器能够从输入句子中

00:00:56.179 --> 00:00:59.144
获取的所有信息

00:00:59.145 --> 00:01:04.935
然后将这个向量发送给解码器 后者使用该向量形成输出句子

00:01:04.935 --> 00:01:07.560
在机器翻译场景中

00:01:07.560 --> 00:01:11.585
编码器和解码器都是循环神经网络

00:01:11.584 --> 00:01:14.464
通常是 LSTM 单元

00:01:14.465 --> 00:01:16.310
在这个场景中

00:01:16.310 --> 00:01:19.700
语境向量是一个数字向量

00:01:19.700 --> 00:01:23.754
表示编码器从输入句子中获取的信息

00:01:23.754 --> 00:01:31.259
在现实中 这个向量的长度会达到 256 或 512 或更高

00:01:31.260 --> 00:01:33.430
为了用图形表示

00:01:33.430 --> 00:01:37.700
我们将隐藏状态显示为这个长度为 4 的向量

00:01:37.700 --> 00:01:40.219
将单元格的亮度看做

00:01:40.219 --> 00:01:43.310
该单元格的值高低程度

00:01:43.310 --> 00:01:45.939
再来看看我们的基本示例

00:01:45.939 --> 00:01:50.629
但是这次将查看编码器的隐藏状态

00:01:50.629 --> 00:01:56.254
第一步是处理第一个单词并生成第一个隐藏状态

00:01:56.254 --> 00:02:01.799
第二步是将第一个隐藏状态中的第二个单词当做 RNN 的输入

00:02:01.799 --> 00:02:04.584
生成第二个隐藏状态

00:02:04.584 --> 00:02:06.184
在第三步

00:02:06.185 --> 00:02:10.935
处理最后一个单词并生成最后一个隐藏状态

00:02:10.935 --> 00:02:16.585
这个隐藏状态将是发送给解码器的语境向量

00:02:16.585 --> 00:02:21.504
现在就要介绍序列到序列模型存在的限制

00:02:21.504 --> 00:02:24.379
无论输入句子有多长

00:02:24.379 --> 00:02:29.000
编码器都只能发送一个向量

00:02:29.000 --> 00:02:32.150
如果为这个向量选择合理的大小

00:02:32.150 --> 00:02:35.634
则在处理很长的输入句子时 模型会遇到问题

00:02:35.633 --> 00:02:40.339
你可能会说 要不在编码器中使用大量隐藏单元

00:02:40.340 --> 00:02:43.069
使语境很庞大

00:02:43.069 --> 00:02:46.930
这样的话 模型在短句子上会过拟合

00:02:46.930 --> 00:02:51.349
当你增加参数数量时 会遇到性能瓶颈

00:02:51.349 --> 00:02:55.269
注意力可以解决这种问题

