<!-- udacimak v1.3.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Machine Translation</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>RNN Keras Lab</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Intro.html">01. Intro</a>
    </li>
    <li class="">
      <a href="02. Machine Translation.html">02. Machine Translation</a>
    </li>
    <li class="">
      <a href="03. Deciphering Code with character-level RNNs.html">03. Deciphering Code with character-level RNNs</a>
    </li>
    <li class="">
      <a href="04. [SOLUTION] Deciphering code with character-level RNNs.html">04. [SOLUTION] Deciphering code with character-level RNNs</a>
    </li>
    <li class="">
      <a href="05. Congratulations!.html">05. Congratulations!</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">02. Machine Translation</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3></h3>
  <div>
  <p>Machine Translation can be thought of as a sequence-to-sequence learning problem.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.002.png" alt="Machine Translation: A Sequence-to-Sequence Learning Problem" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Machine Translation: A Sequence-to-Sequence Learning Problem</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>You have one sequence going in, i.e. a sentence in the source language,<br />
and one sequence coming out, its translation in the target language.</p>
<p>This seems like a very hard problem - and it is! But recent advances in Recurrent Neural Networks have shown a lot of improvement. A typical approach is to use a recurrent layer to encode the meaning of the sentence by processing the words in a sequence, and then either use a dense or fully-connected layer to produce the output, or use another decoding layer.</p>
<p>Experimenting with different network architectures and recurrent layer units (such as LSTMs, GRUs, etc.), you can come up with a fairly simple model that performs decently well on small-to-medium size datasets.<br />
Commercial-grade translation systems need to deal with a much larger vocabulary, and hence have to use a much more complex model, apply different optimizations, etc. Training such models requires a lot of data and compute time.</p>
<h2 id="neural-net-architecture-for-machine-translation">Neural Net Architecture for Machine Translation</h2>
<p>Let's develop a basic neural network architecture for machine translation.</p>
<h3 id="input-representation">Input Representation</h3>
<p>The key thing to note here is that instead of a single word vector or document vector as input, we need to represent each sentence in the source language as a sequence of word vectors.<br />
Therefore, we convert each word or token into a one-hot encoded vector, and stack those vectors into a matrix - this becomes our input to the neural network.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.003.png" alt="Input Representation" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Input Representation</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>You may be wondering what to do about sequences of different length: One common approach is to simply take the sequence of maximum length in your corpus, and pad each sequence with a special token to make them all the same length.</p>
<h3 id="basic-rnn-architecture">Basic RNN Architecture</h3>
<p>Once we have the sequence of word vectors, we can feed them in one at a time to the neural network.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.004.png" alt="Basic RNN Architecture for Machine Translation" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Basic RNN Architecture for Machine Translation</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h4 id="embedding-layer">Embedding Layer</h4>
<p>The first layer of the network is typically an embedding layer that helps enhance the representation of the word. This produces a more compact word vector that is then fed into one or more recurrent layers.</p>
<h4 id="recurrent-layers">Recurrent Layer(s)</h4>
<p>This is where the magic happens! The recurrent layer(s) help incorporate information from across the sequence, allowing each output word to be affected by potentially any previous input word.</p>
<p><em>Note: You could skip the embedding step, and feed in the one-hot encoded vectors directly to the recurrent layer(s). This may reduce the complexity of the model and make it easier to train, but the quality of translation may suffer as one-hot encoded vectors cannot exploit similarities and differences between words.</em></p>
<h4 id="dense-layers">Dense Layer(s)</h4>
<p>The output of the recurrent layer(s) is fed into one or more fully-connected dense layers that produce softmax output, which can be interpreted as one-hot encoded words in the target language.</p>
<p>As each word is passed in as input, its corresponding translation is obtained from the final output. The output words are then collected in a sequence to produce the complete translation of the input sentence.</p>
<p><em>Note: For efficient processing we would like to capture the output in a matrix of fixed size, and for that we need to have output sequences of the same length. Again, we can achieve this by using the same padding technique as we used for input.</em></p>
<h3 id="recurrent-layer-internals">Recurrent Layer: Internals</h3>
<p>Let’s take a closer look at what is going on inside a recurrent layer.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.005.png" alt="Recurrent Layer: Internals" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Recurrent Layer: Internals</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <ul>
<li>The input word vector <span class="mathquill ud-math">x_t</span> is first multiplied by the weight matrix:<br />
<span class="mathquill ud-math">W_x</span></li>
<li>Then bias values are added to produce our first intermediate result:<br />
<span class="mathquill ud-math">x_t W_x + b</span></li>
<li>Meanwhile, the state vector from the previous time step <span class="mathquill ud-math">h_{t-1}</span> is multiplied with another weight matrix <span class="mathquill ud-math">W_h</span> to produce our second intermediate result:<br />
<span class="mathquill ud-math">h_{t-1} W_h</span></li>
<li>These two are then added together, and passed through an activation function such as ReLU, sigmoid or tanh to produce the state for the current time step: <span class="mathquill ud-math">h_t</span></li>
<li>This state vector is passed on as input to the next fully-connected layer, that applies another weight matrix, bias and activation to produce the output: <span class="mathquill ud-math">y_t</span></li>
</ul>
<p>Let’s simplify this diagram and look at the bigger picture again.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.006.png" alt="Basic RNN: Schematic" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Basic RNN: Schematic</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>The key thing to note here is that the RNN’s state <span class="mathquill ud-math">h_t</span> is used to produce the output <span class="mathquill ud-math">y_t</span>, as well as looped back to produce the next state.</p>
<p>In summary, a recurrent layer computes the current state <span class="mathquill ud-math">h_t</span> as:</p>
<blockquote>
  <p><span class="mathquill ud-math">h_t = f(x_t W_x + h_{t-1} W_h + b)</span></p>
</blockquote>
<p>Here <span class="mathquill ud-math">f(\cdot)</span> is some non-linear activation function, <span class="mathquill ud-math">x_t</span> is the input vector, <span class="mathquill ud-math">W_x</span> is the input weight matrix, <span class="mathquill ud-math">h_{t-1}</span> is the previous state vector, <span class="mathquill ud-math">W_h</span> is the recurrent weight matrix and <span class="mathquill ud-math">b</span> is the bias vector.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3><p>RNN Parameters</p></h3>
  <div>
  <p><strong>QUIZ QUESTION:</strong>: <p>Let's say you've decided to use a word vector (<span class="mathquill ud-math">x_t</span>) of length 200, and a state vector (<span class="mathquill ud-math">h_t</span>) of length 300. Treating these as single-row matrices, we can write the sizes as 1x200 and 1x300 respectively.</p>
<p>Now, what is the size of each parameter of the RNN? Match the correct sizes below.</p></p>
  <p><strong>ANSWER CHOICES:</strong></p>
  <button class="btn btn-primary"><p>Input weight matrix (<span class="mathquill ud-math">W_x</span>)</p></button>
  <button class="btn btn-primary"><p>Recurrent weight matrix (<span class="mathquill ud-math">W_h</span>)</p></button>
  <button class="btn btn-primary"><p>Bias vector (<span class="mathquill ud-math">b</span>)</p></button>

  <br><br>

  <table class="table">
    <tr class="thead-dark table-hover">
      <th>
        <p>Parameter</p>
      </th>
      <th>
        <p>Size (rows x cols)</p>
      </th>
    </tr>

    <tr>
      <td><p>300x1</p></td>
      <td></td>
    </tr>
    <tr>
      <td><p>1x300</p></td>
      <td></td>
    </tr>
    <tr>
      <td><p>1x500</p></td>
      <td></td>
    </tr>
    <tr>
      <td><p>300x300</p></td>
      <td></td>
    </tr>
    <tr>
      <td><p>200x200</p></td>
      <td></td>
    </tr>
    <tr>
      <td><p>200x300</p></td>
      <td></td>
    </tr>
    <tr>
      <td><p>300x200</p></td>
      <td></td>
    </tr>
  </table>

  <details>
    <summary><strong>SOLUTION:</strong></summary>

    <table class="table">
      <tr class="thead-dark table-hover">
        <th>
          <p>Parameter</p>
        </th>
        <th>
          <p>Size (rows x cols)</p>
        </th>
      </tr>

      <tr>
        <td>
          <p>1x300</p>
        </td>
        <td>
            <button class="btn btn-primary"><p>Bias vector (<span class="mathquill ud-math">b</span>)</p></button>
        </td>
      </tr>
      <tr>
        <td>
          <p>300x300</p>
        </td>
        <td>
            <button class="btn btn-primary"><p>Recurrent weight matrix (<span class="mathquill ud-math">W_h</span>)</p></button>
        </td>
      </tr>
      <tr>
        <td>
          <p>200x300</p>
        </td>
        <td>
            <button class="btn btn-primary"><p>Input weight matrix (<span class="mathquill ud-math">W_x</span>)</p></button>
        </td>
      </tr>
    </table>
  </details>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h3 id="unrolling-an-rnn">Unrolling an RNN</h3>
<p>It’s easier to understand how this works over time if we unroll it.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.007.png" alt="Basic RNN: Unrolled" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Basic RNN: Unrolled</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>Each copy of the network you see represents its state at the respective time step.<br />
At any time <span class="mathquill ud-math">t</span>, the recurrent layer receives input <span class="mathquill ud-math">x_t</span> as well as the state vector from the previous step, <span class="mathquill ud-math">h_{t-1}</span>. This process is continued till the entire input is exhausted.</p>
<p>The main drawback of such a simple model is that we are trying to read the corresponding output for each input word immediately. This would only work in situations where the source and target language have an almost one-to-one mapping between words.</p>
<h2 id="encoder-decoder-architecture">Encoder-Decoder Architecture</h2>
<p>What we should ideally do is to let the network learn an internal representation of the entire input sentence, and then start generating the output translation. In fact, you need two different networks in order to achieve this.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.008.png" alt="Encoder-Decoder: Unrolled" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Encoder-Decoder: Unrolled</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>The first is called an Encoder, which accepts the source sentence, one word at a time, and captures its overall meaning in a single vector. This is simply the state vector at the last time step. Note that the encoder network is not used to produce any outputs.</p>
<p>The second network is called a Decoder, which then interprets the final sentence vector and expands it into the corresponding sentence in the target language, again one word at a time.</p>
<p>The first time step for the decoder network is special. It is fed in the final sentence vector from the encoder <span class="mathquill ud-math">h_t</span>, and given a sentinel input to kickstart the process. The recurrent portion of the network produces a state vector  <span class="mathquill ud-math">c_0</span>, and with that the fully-connected portion produces the first output word in the target language,  <span class="mathquill ud-math">y_0</span>.</p>
<p>At each subsequent time step t, the decoder network uses its own previous state  <span class="mathquill ud-math">c_{t-1}</span> as well as its own previous output  <span class="mathquill ud-math">y_{t-1}</span>, in order to produce the current output,  <span class="mathquill ud-math">y_t</span>.</p>
<p>This process is typically continued for a fixed number of iterations, with the idea that the network will start producing special padding symbols after all meaningful words have been generated. Alternately, the network could be trained to output a stop symbol, such as a period (.), to indicate that the translation is complete.</p>
<p>If we roll back the time steps, we can see what the overall architecture looks like.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/nlp-m1-l4-machine-translation.009.png" alt="Encoder-Decoder: Schematic" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>Encoder-Decoder: Schematic</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>This encoder-decoder design very popular for several sequence-to-sequence tasks, not just Machine Translation.</p>
<p>Now, there are several variations of this design that can be used to enhance the performance of the network.</p>
<ul>
<li>One option is to use different kinds of recurrent neural network units, such as LSTMs, GRUs etc. instead of vanilla RNN units. That allows the network to better analyze the input sequence, at the cost of additional model complexity.</li>
<li>Another dimension to explore is how many recurrent layers to use. Each layer effectively incorporates information from the input sequence, producing a compact state vector at each time step. Additional layers can essentially incorporate information across these state vectors.</li>
<li>Other more innovative approaches include adding in a backward encoder (bidirectional encoder-decoder model), feeding in the sentence vector to each time step of the decoder (attention mechanism), etc.</li>
</ul>
<p>Feel free to experiment with these different approaches to see what architecture works best for your task. Keep in mind that these mechanisms typically add to the model complexity, which means you need more data and time to train the additional parameters.</p>
</div>

</div>
<div class="divider"></div>
          </div>

          <div class="col-12">
            <p class="text-right">
              <a href="03. Deciphering Code with character-level RNNs.html" class="btn btn-outline-primary mt-4" role="button">Next Concept</a>
            </p>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://github.com/udacimak/udacimak#readme" target="_blank">udacimak v1.3.0</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('02. Machine Translation')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
</body>

</html>
