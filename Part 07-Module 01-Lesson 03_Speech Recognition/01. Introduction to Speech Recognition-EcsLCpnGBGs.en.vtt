WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.870
Hello again. In the last module,

00:00:02.870 --> 00:00:07.985
we built a VUI application that used a commercial implementation of speech recognition.

00:00:07.985 --> 00:00:11.387
Like magic, the words we speak into a voice enabled device,

00:00:11.387 --> 00:00:13.179
are converted into text.

00:00:13.179 --> 00:00:18.489
In this module, we take a closer look at how speech recognition really works.

00:00:18.489 --> 00:00:21.004
Now, when we say speech recognition,

00:00:21.004 --> 00:00:23.524
we're really talking about ASR,

00:00:23.524 --> 00:00:25.534
or automatic speech recognition.

00:00:25.535 --> 00:00:28.445
With ASR, the goal is to simply input

00:00:28.445 --> 00:00:32.704
any continuous audio speech and output the text equivalent.

00:00:32.704 --> 00:00:37.589
We want our ASR to be speaker independent and have high accuracy.

00:00:37.590 --> 00:00:41.468
Such a system has long been a core goal of AI,

00:00:41.468 --> 00:00:44.060
and in the 1980s and 1990s,

00:00:44.060 --> 00:00:48.960
advances in probabilistic models began to make ASR a reality.

00:00:48.960 --> 00:00:50.917
We'll start by asking the question,

00:00:50.917 --> 00:00:53.314
what makes speech recognition hard?

00:00:53.314 --> 00:00:55.549
Like many other AI problems we've seen,

00:00:55.549 --> 00:00:59.704
ASR can be implemented by gathering a large pool of labelled data,

00:00:59.704 --> 00:01:01.714
training a model on that data,

00:01:01.715 --> 00:01:06.530
and then deploying the trained model to accurately label new data.

00:01:06.530 --> 00:01:12.430
The twist is that speech is structured in time and has a lot of variability.

00:01:12.430 --> 00:01:14.900
We'll identify specific challenges we face when

00:01:14.900 --> 00:01:18.065
decoding spoken words and sentences into text.

00:01:18.064 --> 00:01:20.674
To understand how these challenges can be met,

00:01:20.674 --> 00:01:26.734
we'll take a deeper dive into the sound signal itself as well as various speech models.

00:01:26.734 --> 00:01:29.079
The sound signal is our data.

00:01:29.079 --> 00:01:31.129
We'll get into signal analysis,

00:01:31.129 --> 00:01:35.719
phonetics, and how to extract features to represent speech data.

00:01:35.719 --> 00:01:38.989
Models in speech recognition can conceptually be

00:01:38.989 --> 00:01:43.334
divided into an acoustic model and a language model.

00:01:43.334 --> 00:01:46.039
The acoustic model solves the problems of turning

00:01:46.040 --> 00:01:50.060
sound signals into some kind of phonetic representation.

00:01:50.060 --> 00:01:54.004
The language model houses the domain knowledge of words,

00:01:54.004 --> 00:01:57.319
grammar, and sentence structure for the language.

00:01:57.319 --> 00:02:00.049
These conceptual models can be implemented with

00:02:00.049 --> 00:02:03.789
probabilistic models using machine learning algorithms.

00:02:03.790 --> 00:02:09.575
Hidden Markov models have been refined with advances for ASR over a few decades now,

00:02:09.574 --> 00:02:13.384
and are considered the traditional ASR solution.

00:02:13.384 --> 00:02:18.824
Meanwhile, the cutting edge of ASR today is end-to-end Deep Neural Network Models.

00:02:18.824 --> 00:02:21.014
We'll talk about both.

00:02:21.014 --> 00:02:22.774
When you've absorbed all that,

00:02:22.775 --> 00:02:26.406
you'll be ready to build your own ASR in the final project.

00:02:26.406 --> 00:02:30.395
You'll be using deep learning tools you've already been introduced to,

00:02:30.395 --> 00:02:33.490
with a few new twists. Let's get started.

