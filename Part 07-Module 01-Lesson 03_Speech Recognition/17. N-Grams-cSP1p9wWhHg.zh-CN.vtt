WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.970
语言模型的工作

00:00:02.970 --> 00:00:07.970
就是在语音识别时 把语言知识注入到单词与文本这两步之间

00:00:07.969 --> 00:00:11.400
在单词和文本之间加一个处理层

00:00:11.400 --> 00:00:16.170
从而解决拼写和语境造成的语义模糊

00:00:16.170 --> 00:00:20.429
打个比方 由于声学模型是以声音为依据的

00:00:20.429 --> 00:00:25.490
所以无法判断发音一样的单词应有什么拼写

00:00:25.490 --> 00:00:28.559
比如 here 和 hear

00:00:28.559 --> 00:00:34.725
其它排序方式可能说不通 但只需多加一点信息 我们就可以进行校正

00:00:34.725 --> 00:00:39.990
声学模型生成的单词并不是绝对之选

00:00:39.990 --> 00:00:45.795
我们可以把这些单词想成是诸多不同单词的概率分布

00:00:45.795 --> 00:00:49.829
我们可以计算各候选序列

00:00:49.829 --> 00:00:54.564
是由音频信号生成的特定单词的概率

00:00:54.564 --> 00:01:01.829
数据语言模型提供了不同词序的概率分布

00:01:01.829 --> 00:01:03.509
如果我们两者都有

00:01:03.509 --> 00:01:06.498
既有声学模型又有语言模型

00:01:06.498 --> 00:01:10.185
那么最可能的序列

00:01:10.185 --> 00:01:14.909
就是概率值最高的概率组合

00:01:14.909 --> 00:01:18.842
如果要把两个模型的概率都求出来

00:01:18.843 --> 00:01:23.400
运算维数会十分庞大

00:01:23.400 --> 00:01:29.715
但我们可以根据有限的选择深度来进行估算

00:01:29.715 --> 00:01:32.025
原来 在实际应用中

00:01:32.025 --> 00:01:35.490
我们在任意时间点说出的单词

00:01:35.489 --> 00:01:40.474
主要只与前三个或四个单词有关

00:01:40.474 --> 00:01:45.419
N 元模型是一个单词、两个有序单词、

00:01:45.420 --> 00:01:49.079
三个有序单词等的概率模型 用 N 元模型

00:01:49.079 --> 00:01:52.980
我们就可以用链式法则来估算序列概率

00:01:52.980 --> 00:01:57.990
用第一个单词发生的概率乘以

00:01:57.989 --> 00:02:04.019
以第一个单词为前提的第二个单词发生的概率 以此类推进行乘法 我们就能得到给定序列的概率

00:02:04.019 --> 00:02:06.750
然后结合这些概率和

00:02:06.750 --> 00:02:09.840
声学模型的概率 进行比较

00:02:09.840 --> 00:02:13.140
从而解决排序方式造成的语义模糊问题

00:02:13.139 --> 00:02:17.059
更好地预测文本表述

