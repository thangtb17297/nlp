WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.754
现在我们有了数据

00:00:01.754 --> 00:00:04.769
而且用特征提取解决了噪声问题

00:00:04.769 --> 00:00:08.695
噪声是由环境因素以及说话者的差异引起的

00:00:08.695 --> 00:00:13.635
语音学为我们提供了声音和语言的表征方法 使我们能够进行映射

00:00:13.634 --> 00:00:18.329
将声音表征映射成语音表征

00:00:18.329 --> 00:00:21.359
是声学模型的任务

00:00:21.359 --> 00:00:26.625
我们还没有解决同一个单词有多种长度的问题

00:00:26.625 --> 00:00:30.320
在另一课里我们谈过这个问题

00:00:30.320 --> 00:00:33.780
当时我们介绍了动态时间规整 (DTW) 算法

00:00:33.780 --> 00:00:39.359
重温一下 DTW 计算的是两个信号的相似度

00:00:39.359 --> 00:00:42.295
不受信号时长的影响

00:00:42.295 --> 00:00:45.075
同样的技术可用于语音识别

00:00:45.075 --> 00:00:48.359
比如把新词的序列数据与

00:00:48.359 --> 00:00:52.545
词例字典里同其最接近的对象对齐

00:00:52.545 --> 00:00:54.240
很快我们就能看到

00:00:54.240 --> 00:00:58.020
隐马尔可夫模型也很适合解决

00:00:58.020 --> 00:01:02.640
声学模型里这类涉及时间序列模式的排序问题

00:01:02.640 --> 00:01:05.519
就是因为这种适用性 所以过去三十年里

00:01:05.519 --> 00:01:09.524
人们常用这类模型来解决语音识别问题

00:01:09.525 --> 00:01:13.380
如果我们用深度神经网络来处理声学模型

00:01:13.379 --> 00:01:15.899
排序问题又会出现

00:01:15.900 --> 00:01:20.415
我们可以结合 HMM 和 DNN 系统来解决这一问题

00:01:20.415 --> 00:01:23.250
也可以用别的办法

00:01:23.250 --> 00:01:27.150
稍后我们会讲如何用 DNN

00:01:27.150 --> 00:01:32.340
和联结主义时序分类 CTC 来解决这类问题

00:01:32.340 --> 00:01:37.530
不过我们先来回顾 HMM 的知识 复习 HMM 在语音识别里的用处

