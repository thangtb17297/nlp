WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.750
Continuous speech recognition has had a rocky history.

00:00:03.750 --> 00:00:06.019
In the early 1970's,

00:00:06.019 --> 00:00:10.449
the United States funded ASR research with a DARPA challenge.

00:00:10.449 --> 00:00:15.980
The goal was to develop a recognizer for a 1000 word vocabulary.

00:00:15.980 --> 00:00:20.260
The goal was achieved a few years later by Carnegie-Mellon's Harpy System.

00:00:20.260 --> 00:00:24.445
But the future prospects were disappointing and funding dried up.

00:00:24.445 --> 00:00:28.635
This was the start of the first big AI Winter.

00:00:28.635 --> 00:00:34.590
Performance improved in the 80's and 90's with refinement of probabilistic models.

00:00:34.590 --> 00:00:36.990
More recently computing power has made

00:00:36.990 --> 00:00:40.410
larger dimensions in neural network modeling a reality.

00:00:40.409 --> 00:00:43.354
So what makes speech recognition hard?

00:00:43.354 --> 00:00:45.569
The first set of problems to solve are related to

00:00:45.570 --> 00:00:49.289
the audio signal itself, noise for instance.

00:00:49.289 --> 00:00:53.429
Cars going by, clocks ticking, other people talking,

00:00:53.429 --> 00:00:57.060
microphones static, our ASR has to know

00:00:57.060 --> 00:01:01.920
which parts of the audio signal matter and which parts to discard.

00:01:01.920 --> 00:01:03.570
Variability of pitch.

00:01:03.570 --> 00:01:05.265
Variability of volume.

00:01:05.265 --> 00:01:10.030
One speaker sounds different than another even when saying the same word.

00:01:10.030 --> 00:01:12.750
The pitch and loudness at least in English don't change

00:01:12.750 --> 00:01:16.165
the ground truth of which word was spoken.

00:01:16.165 --> 00:01:18.510
If I say hello,

00:01:18.510 --> 00:01:22.693
or hello, or hello.

00:01:22.692 --> 00:01:25.590
It's all the same word and spelling.

00:01:25.590 --> 00:01:28.400
We could even think of these differences as

00:01:28.400 --> 00:01:31.870
another kind of noise that needs to be filtered out.

00:01:31.870 --> 00:01:34.115
Variability of words speed.

00:01:34.114 --> 00:01:38.629
Words spoken at different speeds need to be aligned and matched.

00:01:38.629 --> 00:01:42.079
If I say speech or speech,

00:01:42.079 --> 00:01:45.424
it's still the same word with the same number of letters.

00:01:45.424 --> 00:01:50.599
It's up to the ASR to align the sequences of sound correctly.

00:01:50.599 --> 00:01:52.459
Word boundaries.

00:01:52.459 --> 00:01:56.509
When we speak words run from one to the next without pause.

00:01:56.510 --> 00:02:01.948
We don't separate them naturally.

00:02:01.947 --> 00:02:04.309
Humans understand it because we already

00:02:04.310 --> 00:02:08.235
know that the word boundaries should be in certain places.

00:02:08.235 --> 00:02:13.500
This brings us to another class of problems that are language or knowledge related.

00:02:13.500 --> 00:02:18.324
The fact is, humans perceive speech with more than just their ears.

00:02:18.324 --> 00:02:21.589
We have domain knowledge of our language that allows us

00:02:21.590 --> 00:02:25.594
to automatically sort out ambiguities as we hear them.

00:02:25.594 --> 00:02:29.395
Words that sound the same but have different spellings.

00:02:29.395 --> 00:02:33.980
Word groups that are reasonable in one context but not in another.

00:02:33.979 --> 00:02:36.144
Here's a classic example.

00:02:36.145 --> 00:02:38.765
When I say recognize speech,

00:02:38.764 --> 00:02:41.764
it sounds a lot like recognize speech.

00:02:41.764 --> 00:02:46.419
But you knew what I meant because you know I'm discussing speech recognition.

00:02:46.419 --> 00:02:48.094
The context matters.

00:02:48.094 --> 00:02:52.490
An inference like this is going to be tricky for a computer model.

00:02:52.490 --> 00:02:54.314
Another aspect to consider.

00:02:54.314 --> 00:02:57.710
Spoken language is different than written language.

00:02:57.710 --> 00:03:01.610
There are hesitations, repetitions, fragments of sentences,

00:03:01.610 --> 00:03:02.930
slips of the tongue,

00:03:02.930 --> 00:03:06.560
a human listener is able to filter this out.

00:03:06.560 --> 00:03:12.824
Imagine a computer that only knows language from audio books and newspapers read aloud.

00:03:12.824 --> 00:03:18.239
Such a system may have a hard time decoding unexpected sentence structures.

00:03:18.240 --> 00:03:21.770
Okay, we've identified lots of problems to solve here.

00:03:21.770 --> 00:03:25.175
Variability of pitch, volume, and speed,

00:03:25.175 --> 00:03:29.915
ambiguity due to word boundaries, spelling, and context.

00:03:29.914 --> 00:03:32.150
We're going to introduce some ways to solve

00:03:32.150 --> 00:03:35.575
these problems with a number of models and technologies.

00:03:35.574 --> 00:03:39.000
We'll start at the beginning with the voice itself.

