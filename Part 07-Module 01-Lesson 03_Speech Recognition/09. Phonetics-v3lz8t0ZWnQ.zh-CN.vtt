WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.710
语音学是研究人类语音的学科

00:00:03.710 --> 00:00:07.189
语言分析

00:00:07.190 --> 00:00:11.105
会将人类语言切分成最小的音段

00:00:11.105 --> 00:00:12.755
对于任一种语言

00:00:12.755 --> 00:00:18.410
我们可以用若干音位来定义不同的发音

00:00:18.410 --> 00:00:24.394
在美国英语中 大概有 39 到 44 个音位

00:00:24.394 --> 00:00:26.794
相反 一个字母

00:00:26.795 --> 00:00:31.130
则是书面语的最小独立单元

00:00:31.129 --> 00:00:34.310
美国英语能定义的最小字素集

00:00:34.310 --> 00:00:39.690
是字母表的 26 个字母加上一个空格

00:00:39.689 --> 00:00:42.589
很遗憾 我们没有办法将

00:00:42.590 --> 00:00:46.190
音位与字素或与单个字母对应起来

00:00:46.189 --> 00:00:49.280
因为有些字母对应多个音位

00:00:49.280 --> 00:00:53.005
有些音位则不仅对应一种字母组合

00:00:53.005 --> 00:01:00.645
比如 英语里的字母 C 在 cat、chat 和 circle 里的发音都不一样

00:01:00.645 --> 00:01:05.570
而我们在 receive、beet 和 beat 里听到的音位 E

00:01:05.569 --> 00:01:11.629
又是以不同的字母组合表示的

00:01:11.629 --> 00:01:16.189
这是美国英语音位集的一个样本 叫做 Arpabet

00:01:16.189 --> 00:01:21.890
Arpabet 于 1971 年开发而出 旨在研究语音识别

00:01:21.890 --> 00:01:24.320
其中包括 39 个音位

00:01:24.319 --> 00:01:27.500
15 个元音和 24 个辅音

00:01:27.500 --> 00:01:31.564
每个元音或辅音都由一个或两个字母符号表示

00:01:31.564 --> 00:01:34.429
要查看整个集合 请查阅参考部分

00:01:34.430 --> 00:01:39.535
音位往往是语音和文本间的实用媒介

00:01:39.534 --> 00:01:44.179
如果我们能建立一种声学模型 将声音信号解码成音位

00:01:44.180 --> 00:01:50.450
那剩下的工作就只是将音位与相应的单词匹配起来了

00:01:50.450 --> 00:01:53.180
这个过程叫词汇解码

00:01:53.180 --> 00:01:57.830
需要依赖数据集的词典或字典来进行

00:01:57.829 --> 00:02:02.765
为什么不将声学模型直接翻译成文字呢？

00:02:02.765 --> 00:02:05.859
为什么要有中间这一步？

00:02:05.859 --> 00:02:08.360
这是个很好的问题

00:02:08.360 --> 00:02:11.660
还真有些系统能把特征直接翻译成文字

00:02:11.659 --> 00:02:16.150
这取决于设计目的和问题的维数

00:02:16.150 --> 00:02:20.784
如果我们想训练的词汇数量有限 那我们可以跳掉音位这一步

00:02:20.784 --> 00:02:24.935
但如果词汇量很大 那就要先转换成较小的单元

00:02:24.935 --> 00:02:29.140
以便减少整个系统需要进行的对比数

