<!-- udacimak v1.3.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>References: Feature Extraction</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>Speech Recognition</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Intro.html">01. Intro</a>
    </li>
    <li class="">
      <a href="02. Challenges in ASR.html">02. Challenges in ASR</a>
    </li>
    <li class="">
      <a href="03. Signal Analysis.html">03. Signal Analysis</a>
    </li>
    <li class="">
      <a href="04. References Signal Analysis.html">04. References: Signal Analysis</a>
    </li>
    <li class="">
      <a href="05. Quiz FFT.html">05. Quiz: FFT</a>
    </li>
    <li class="">
      <a href="06. Feature Extraction with MFCC.html">06. Feature Extraction with MFCC</a>
    </li>
    <li class="">
      <a href="07. References Feature Extraction.html">07. References: Feature Extraction</a>
    </li>
    <li class="">
      <a href="08. Quiz MFCC.html">08. Quiz: MFCC</a>
    </li>
    <li class="">
      <a href="09. Phonetics.html">09. Phonetics</a>
    </li>
    <li class="">
      <a href="10. References Phonetics.html">10. References: Phonetics</a>
    </li>
    <li class="">
      <a href="11. Quiz Phonetics.html">11. Quiz: Phonetics</a>
    </li>
    <li class="">
      <a href="12. Voice Data Lab Introduction.html">12. Voice Data Lab Introduction</a>
    </li>
    <li class="">
      <a href="13. Lab Voice Data.html">13. Lab: Voice Data</a>
    </li>
    <li class="">
      <a href="14. Acoustic Models and the Trouble with Time.html">14. Acoustic Models and the Trouble with Time</a>
    </li>
    <li class="">
      <a href="15. HMMs in Speech Recognition.html">15. HMMs in Speech Recognition</a>
    </li>
    <li class="">
      <a href="16. Language Models.html">16. Language Models</a>
    </li>
    <li class="">
      <a href="17. N-Grams.html">17. N-Grams</a>
    </li>
    <li class="">
      <a href="18. Quiz N-Grams.html">18. Quiz: N-Grams</a>
    </li>
    <li class="">
      <a href="19. References Traditional ASR.html">19. References: Traditional ASR</a>
    </li>
    <li class="">
      <a href="20. A New Paradigm.html">20. A New Paradigm</a>
    </li>
    <li class="">
      <a href="21. Deep Neural Networks as Speech Models.html">21. Deep Neural Networks as Speech Models</a>
    </li>
    <li class="">
      <a href="22. Connectionist Tempora Classification (CTC).html">22. Connectionist Tempora Classification (CTC)</a>
    </li>
    <li class="">
      <a href="23. References Deep Neural Network ASR.html">23. References: Deep Neural Network ASR</a>
    </li>
    <li class="">
      <a href="24. Outro.html">24. Outro</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">07. References: Feature Extraction</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3></h3>
  <div>
  <h1 id="references-feature-extraction">References: Feature Extraction</h1>
<h3 id="feature-extraction">Feature Extraction</h3>
<p>A summary of methods used in ASR:</p>
<p><a href="http://www.ijcsmc.com/docs/papers/March2015/V4I3201545.pdf" target="_blank">Narang, Shreya, and Ms Divya Gupta. "Speech Feature Extraction Techniques: A Review." International Journal of Computer Science and Mobile Computing 4.3 (2015): 107-114.</a></p>
<h3 id="mel-scale">Mel Scale</h3>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/mel-scale.png" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>The Mel Scale was developed in 1937 and is based on human studies of pitch perception.  At lower pitches (frequencies), humans can distinguish pitches better.  Read more about it in <a href="https://en.wikipedia.org/wiki/Mel_scale" target="_blank">Wikipedia</a></p>
<h3 id="the-sourcefilter-model">The Source/Filter Model</h3>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/source-filter-model.png" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>The source/filter model holds that the "source" of voices speech is dependent upon the vibrations initiated in the vocal box, and is unique to the speaker, while the "filter" is the articulation of the words in the forward part of the voice tract.  The two can be separated through Cepstrum Analysis.  A detailed explanation of the Source/Filter model for speech can be found at:</p>
<p><a href="http://web.science.mq.edu.au/~cassidy/comp449/html/ch07.html#d0e1094" target="_blank">Cassidy, Steve. "Speech recognition." Sydney Australia (2002): Chapter 7.</a></p>
<h3 id="cepstral-analysis">Cepstral Analysis</h3>
<p>The source/filter model motivates Cepstral Analysis. The intuition is that the "source" <span class="mathquill ud-math">e(n)</span> is multiplied by the "filter" <span class="mathquill ud-math">h(n)</span> to form the signal, <span class="mathquill ud-math">s(n)</span>:</p>
<p><span class="mathquill ud-math">s(n) = e(n)\times h(n)</span></p>
<p>This signal can be converted to the frequency domain through a discrete Fourier transform, or DFT (can use the FFT algorithm):</p>
<p><span class="mathquill ud-math">\left |S(\omega)  \right |  = \left |E(\omega)  \right | \cdot \left |H(\omega)  \right |</span></p>
<p>Take the log and we can just add the source and filter instead of multiplying:</p>
<p><span class="mathquill ud-math">\log\left |S(\omega)  \right |  = \log\left |E(\omega)  \right |+\log\left |H(\omega)  \right |</span></p>
<p>Here's where it gets a bit tricky.  By taking the inverse discrete Fourier transform, or IDFT, the signal can be split.  This is the cepstrum  <span class="mathquill ud-math">c(n)</span> .  Here's the final equation:</p>
<p><span class="mathquill ud-math">c(n) = IDFT(\log\left |S(\omega)  \right |)  = IDFT(\log\left |E(\omega)  \right |+\log\left |H(\omega)  \right |)</span></p>
<p>Because we are splitting the logs of the frequencies, this is not the same as the original time domain, but rather now called the <em>quefrency</em> or <em>cepstral</em> domain.  The vocal tract, or filter components that we want, can be extracted now because they vary slowly and are concentrated in the lower quefrency region.</p>
<p>Read more in the following thorough treatment complete with diagrams:</p>
<p><a href="http://iitg.vlab.co.in/?sub=59&brch=164&sim=615&cnt=1" target="_blank">Cepstral Analysis of Speech (Theory) : Speech Signal Processing Laboratory : Electronics & Communications : IIT GUWAHATI Virtual Lab</a></p>
<h3 id="mfcc">MFCC</h3>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/mfcc.png" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>Mel Frequency Cepstrum Coefficient Analysis is the reduction of an audio signal to essential speech component features using both mel frequency analysis and cepstral analysis.  The range of frequencies are reduced and binned into groups of frequencies that humans can distinguish.  The signal is further separated into source and filter so that variations between speakers unrelated to articulation can be filtered away.  The following reference provides nice visualizations of the process of audio-&gt;spectrogram-&gt;MFCC:</p>
<p><a href="http://www.speech.cs.cmu.edu/15-492/slides/03_mfcc.pdf" target="_blank">Prahallad, Kishore. "Speech Technology: A Practical Introduction, topic: Spectrogram, Cepstrum and Mel-Frequency Analysis." Carnegie Mellon University</a> </p>
<h3 id="mfcc-deltas-and-delta-deltas">MFCC Deltas and Delta-Deltas</h3>
<p>Intuitively, it makes sense that changes in frequencies, <em>deltas</em>, and changes in changes in frequencies, <em>delta-deltas</em>, might also be meaningful features in speech recognition.  The following succinct tutorial for MFCC's includes a short discussion on deltas and delta-deltas:</p>
<p><a href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/" target="_blank">Mel Frequency Cepstral Coefficient (MFCC) tutorial. Practical Cryptography</a> </p>
</div>

</div>
<div class="divider"></div>
          </div>

          <div class="col-12">
            <p class="text-right">
              <a href="08. Quiz MFCC.html" class="btn btn-outline-primary mt-4" role="button">Next Concept</a>
            </p>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://github.com/udacimak/udacimak#readme" target="_blank">udacimak v1.3.0</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('07. References: Feature Extraction')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
</body>

</html>
