WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.190
在之前的课程里 你学习了隐马尔可夫模型 (HMM) 的基础知识

00:00:05.190 --> 00:00:10.164
重温一下 HMM 擅于检测与时间有关的模式

00:00:10.164 --> 00:00:14.349
而这正是我们想对声学模型进行的操作

00:00:14.349 --> 00:00:16.350
HMM 能解决

00:00:16.350 --> 00:00:19.859
我们之前提出的挑战 即时间差异性

00:00:19.859 --> 00:00:25.244
比如 我之前举的例子 speech 的两种读法

00:00:25.245 --> 00:00:28.255
虽然单词一样 但语速不同

00:00:28.254 --> 00:00:32.519
我们可以用有标签的时序序列来训练 HMM

00:00:32.520 --> 00:00:37.630
为各特定声音单元创建 HMM 模型

00:00:37.630 --> 00:00:39.615
这些单元可以是音位、

00:00:39.615 --> 00:00:43.609
音节、单词 甚至是词组

00:00:43.609 --> 00:00:46.009
训练和识别其实很简单

00:00:46.009 --> 00:00:49.379
只要我们用分离好的单元做训练和测试数据即可

00:00:49.380 --> 00:00:51.557
收集大量例子

00:00:51.557 --> 00:00:55.174
进行训练 为每个单词生成模型

00:00:55.174 --> 00:00:58.409
这样一来 单词识别

00:00:58.409 --> 00:01:02.719
其实就是比较每个模型的新观测概率值

00:01:02.719 --> 00:01:05.819
但如果训练数据包含连续的短语或句子 也即表述

00:01:05.819 --> 00:01:10.949
那过程就复杂许多了

00:01:10.950 --> 00:01:15.350
训练时 我们要怎么分离一系列的音位或单词呢？

00:01:15.349 --> 00:01:18.269
比如这里 单词 brick

00:01:18.269 --> 00:01:23.219
与其它九种表述无间断地连在一起

00:01:23.219 --> 00:01:28.965
要用连续表述来训练 我们可以把 HMM 一对对地组合起来

00:01:28.965 --> 00:01:32.585
把这些连接符也定义成 HMM

00:01:32.584 --> 00:01:35.579
具体说来 我们可以训练 her brick (她的砖)、

00:01:35.579 --> 00:01:38.219
my brick (我的砖)、a brick (一块砖)、

00:01:38.219 --> 00:01:41.129
brick house (砖房)、brick walkway (砖道)、

00:01:41.129 --> 00:01:46.164
和 brick wall (砖墙) 也就是让相连的状态组成一对

00:01:46.165 --> 00:01:48.435
这会增加维数

00:01:48.435 --> 00:01:52.215
不仅需要给每个单词建立 HMM

00:01:52.215 --> 00:01:55.395
还要给每条可能的工作连接建立 HMM

00:01:55.394 --> 00:01:59.689
如果单词很多 那需要的 HMM 就多了

00:01:59.689 --> 00:02:03.134
同样的原则也适用于音位

00:02:03.135 --> 00:02:05.085
但如果词汇量很大

00:02:05.084 --> 00:02:09.299
用音位 维数增长就不会像用单词那么夸张

00:02:09.300 --> 00:02:11.259
如果一组有 40 个音位

00:02:11.258 --> 00:02:15.659
我们就需要 1600 个 HMM 来进行转换

00:02:15.659 --> 00:02:17.870
这个数字仍在可控范围

00:02:17.870 --> 00:02:21.509
训练好后 我们就可以用 HMM 模型

00:02:21.509 --> 00:02:25.289
给各可能路径链所产生的新表述评分 也即求得相应的概率

