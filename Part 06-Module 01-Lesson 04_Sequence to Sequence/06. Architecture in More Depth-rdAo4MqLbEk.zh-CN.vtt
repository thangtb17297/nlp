WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.819
现在我们已经查看了该网络的

00:00:02.819 --> 00:00:06.150
输入和输出展开示例 我们再深入一层

00:00:06.150 --> 00:00:09.220
看看该模型的一些参数

00:00:09.220 --> 00:00:10.950
学到本课程的这一阶段后

00:00:10.949 --> 00:00:14.009
你已经知道我们不能直接向网络提供单词

00:00:14.009 --> 00:00:17.190
我们首先需要将单词转换为向量

00:00:17.190 --> 00:00:20.010
这和我们在 word2vec

00:00:20.010 --> 00:00:23.010
及情感分析 RNN 课程中见到的概念是一样的

00:00:23.010 --> 00:00:25.980
第一组参数是

00:00:25.980 --> 00:00:27.839
我们用来与输入相乘的权重

00:00:27.839 --> 00:00:30.570
每次传入一个元素

00:00:30.570 --> 00:00:32.140
澄清下

00:00:32.140 --> 00:00:34.240
你不需要太担心这一步

00:00:34.240 --> 00:00:37.320
Tensorflow 已经在后台帮你处理

00:00:37.320 --> 00:00:40.926
它会帮助你实施很多部分

00:00:40.926 --> 00:00:42.759
所以暂时不用担心如何实现

00:00:42.759 --> 00:00:44.879
只需大概了解下

00:00:44.880 --> 00:00:46.080
基本概念就行

00:00:46.079 --> 00:00:47.870
稍后我们将介绍如何实现

00:00:47.871 --> 00:00:52.800
实际上 Tensorflow 会帮助我们实现的

00:00:52.799 --> 00:00:55.599
但了解下理论知识还是有帮助的

00:00:55.600 --> 00:01:03.539
这里的 U 表示与输入相乘的

00:01:03.539 --> 00:01:05.280
权重矩阵

00:01:05.280 --> 00:01:08.189
这里是与编码器阶输出的值相乘的A 矩阵

00:01:08.189 --> 00:01:11.980
每个时间步长都会有和A矩阵

00:01:11.980 --> 00:01:15.390
和编码器输出的值相乘并最后输出到解码器中

00:01:15.390 --> 00:01:19.379
然后是另一个权重矩阵 叫做 V

00:01:19.379 --> 00:01:24.229
当解码器输出隐藏状态的值时

00:01:24.230 --> 00:01:27.060
我们用V与之相乘

00:01:27.060 --> 00:01:31.560
另一个是 B 它处于解码器时间步长之间

00:01:31.560 --> 00:01:36.120
传播时会与隐藏状态相乘

00:01:36.120 --> 00:01:39.060
此类模型的最后一个重要组件是

00:01:39.060 --> 00:01:41.549
在输出端的完全连接层

00:01:41.549 --> 00:01:43.530
负责将网络状态

00:01:43.530 --> 00:01:45.930
转换为我们可以选择的输出

00:01:45.930 --> 00:01:48.240
这些将是输出值

00:01:48.239 --> 00:01:50.280
这些输出值的数量

00:01:50.280 --> 00:01:53.480
与我们的词汇大小相同

00:01:53.480 --> 00:01:56.730
包含最大值的输出值的的对应的是

00:01:56.730 --> 00:01:58.680
模型想要输出的单词

00:01:58.680 --> 00:01:59.955
我们看个示例

00:01:59.954 --> 00:02:01.079
详细了解下

00:02:01.079 --> 00:02:05.349
我们看看这个简单的词汇表

00:02:05.349 --> 00:02:08.549
假设只有一个输入和输出示例

00:02:08.550 --> 00:02:15.090
How are you? I am good 词汇大小是 11

00:02:15.090 --> 00:02:16.500
前四个别管

00:02:16.500 --> 00:02:17.879
这些是设定好的

00:02:17.879 --> 00:02:20.400
稍后将用到

00:02:20.400 --> 00:02:22.689
我们将词汇表中的前四个

00:02:22.689 --> 00:02:28.020
保留为 PAD EOS（表示句子结束）

00:02:28.020 --> 00:02:31.240
UNK（表示未知）然后是 GO

00:02:31.240 --> 00:02:34.110
我们已经见过 GO

00:02:34.110 --> 00:02:39.270
我们稍后在实现阶段将详细介绍

00:02:39.270 --> 00:02:41.800
然后是训练数据中

00:02:41.800 --> 00:02:46.530
实际用到的单词列表

00:02:46.530 --> 00:02:47.800
这就是我们的词汇表

00:02:47.800 --> 00:02:50.280
有 11 个元素

00:02:50.280 --> 00:02:53.969
在解码器的每个时间步长

00:02:53.969 --> 00:02:56.370
该网络的输出将根据训练数据

00:02:56.370 --> 00:03:00.090
告诉我们哪个元素

00:03:00.090 --> 00:03:01.650
最有可能被生成

00:03:01.650 --> 00:03:05.159
这是个很小的示例 词汇表很小

00:03:05.159 --> 00:03:07.109
在实际操作中

00:03:07.110 --> 00:03:15.090
你会遇到有数千个示例的词汇表

00:03:15.090 --> 00:03:19.379
所以网络的最后一个层级

00:03:19.379 --> 00:03:20.370
将有数千个输出值

00:03:20.370 --> 00:03:25.140
幸运的是 这可能是

00:03:25.139 --> 00:03:27.719
你最后一次需要查看该网络的这一结构

00:03:27.719 --> 00:03:30.469
Tensorflow 定义了一个序列到序列 API

00:03:30.469 --> 00:03:33.270
将很多这种细节都隐藏起来了

00:03:33.270 --> 00:03:36.240
你只需使用该 API 来定义

00:03:36.240 --> 00:03:38.463
你希望网络如何工作

